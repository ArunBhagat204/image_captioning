{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import math\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):    \n",
    "    file= open('results.csv','r',encoding='utf-8')\n",
    "    text=file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_descriptions():\n",
    "    mapping=dict()\n",
    "    text=load_doc('results.csv')\n",
    "    for line in text.split('\\n'):\n",
    "        tokens=line.split('|')\n",
    "        #print(tokens[0],\" \",tokens[1:],end='\\n')\n",
    "        image_id,image_desc=tokens[0],tokens[-1]\n",
    "        image_id=image_id.split('.')[0]\n",
    "        \n",
    "        if image_id not in mapping:\n",
    "            mapping[image_id]=list()\n",
    "        mapping[image_id].append(image_desc)\n",
    "        \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "descriptions=load_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(descriptions.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions['1000268201']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions['1000344755']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(descriptions):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    for key,desc_list in descriptions.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            desc=desc_list[i]\n",
    "            desc=desc.split()\n",
    "            desc=[word.lower() for word in desc]\n",
    "            desc=[w.translate(table) for w in desc]\n",
    "            desc=[word for word in desc if len(word)>1]\n",
    "            desc=[word for word in desc if word.isalpha()]\n",
    "            desc_list[i]=' '.join(desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions['1000344755']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions['1000268201']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_descriptions(descriptions,filename):\n",
    "    lines=list()\n",
    "    for key,desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key+' '+desc)\n",
    "    data='\\n'.join(lines)\n",
    "    \n",
    "    file=open(filename,'w')\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_desc=set()\n",
    "for key in descriptions.keys():\n",
    "    #print(key)\n",
    "    for d in descriptions[key]:\n",
    "        [all_desc.update(d.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=all_desc\n",
    "print(\"size of the vocabulary=\",len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set(filename):\n",
    "    doc=load_doc(filename)\n",
    "    dataset=list()\n",
    "    for line in doc.split('\\n'):\n",
    "        if len(line)<1:\n",
    "            continue\n",
    "        identifier=line.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return set(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='results.csv'\n",
    "train=load_set(filename)\n",
    "print('dataset=',len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images='./flickr30k_images/flickr30k_images/'\n",
    "img=glob.glob(images+'*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    img=image.load_img(image_path)\n",
    "    size=img.size\n",
    "    if(size[0]>size[1]):\n",
    "        (size_max,size_min)=(size[0],size[1])\n",
    "        border_dir='v'\n",
    "    else:\n",
    "        (size_max,size_min)=(size[1],size[0])\n",
    "        border_dir='h'\n",
    "    border_amount=math.ceil((size_max-size_min)/2)\n",
    "    if (border_dir == 'v'):\n",
    "        img = ImageOps.expand(img,border=(0,border_amount),fill='white')\n",
    "    else:\n",
    "        img = ImageOps.expand(img,border=(border_amount,0),fill='white')\n",
    "    \n",
    "    img = img.resize((299,299),resample=0)\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    x=preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new=Model(model.input,model.layers[-2].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(image):\n",
    "    image=preprocess(image)\n",
    "    fea_vec=model_new.predict(image)\n",
    "    fea_vec=np.reshape(fea_vec,fea_vec.shape[1])\n",
    "    return fea_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time()\n",
    "encoding_train={}\n",
    "for img in img:\n",
    "    encoding_train[img[len(images):]]=encode(img)\n",
    "    print(\"time tken in second=\",time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoded_train_images.pkl','wb') as f:\n",
    "    dump(encoding_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=load(open('encoded_train_images.pkl','rb'))\n",
    "print(len(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_train_captions=[]\n",
    "for key,val in descriptions.items():\n",
    "    for cap in val:\n",
    "        all_train_captions.append(cap)\n",
    "len(all_train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_threshold=10\n",
    "word_counts={}\n",
    "nsents=0\n",
    "for sent in all_train_captions:\n",
    "    nsents+=1\n",
    "    for w in sent.split(' '):\n",
    "        word_counts[w]=word_counts.get(w,0)+1\n",
    "        \n",
    "vocab=[w for w in word_counts if word_counts[w]>=word_count_threshold]\n",
    "print(\"no of word =\",len(word_counts))\n",
    "print(\"len of vocabulary=\",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtoword={}\n",
    "wordtoix={}\n",
    "ix=1\n",
    "for w in vocab:\n",
    "    wordtoix[w]=ix\n",
    "    ixtoword[ix]=w\n",
    "    ix+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ixtoword.pkl','wb') as f1:\n",
    "    dump(ixtoword,f1)\n",
    "    f1.close()\n",
    "\n",
    "with open('wordtoix.pkl','wb') as f2:\n",
    "    dump(wordtoix,f2)\n",
    "    f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(ixtoword)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lines(descriptions):\n",
    "    all_desc=list()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(to_lines(descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(descriptions):\n",
    "    lines=to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=max_length(descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of max length descriptions=\",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(descriptions,photos,wordtoix,max_length,num_photos_per_batch):\n",
    "    X1,X2,y=list(),list(),list()\n",
    "    n=0\n",
    "    \n",
    "    while 1:\n",
    "        for key,desc_list in descriptions.items():\n",
    "            n+=1\n",
    "            photo=photos[key+'.jpg']\n",
    "            for desc in desc_list:\n",
    "                seq=[wordtoix[word] for word in desc.split(' ') if word in wordtoix ]\n",
    "                for i in range(1,len(seq)):\n",
    "                    in_seq,out_seq=seq[:i],seq[i]\n",
    "                    in_seq=pad_sequences([in_seq],maxlen=max_length)[0]\n",
    "                    \n",
    "                    out_seq=to_categorical([out_seq],num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                    \n",
    "            if n==num_photos_per_batch:\n",
    "                yield [[array(X1),array(X2)],array(y)]\n",
    "                X1,X2,y=list(),list(),list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir='glove.6B.200d.txt'\n",
    "embedding_index={}\n",
    "\n",
    "f=open(glove_dir,encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float32')\n",
    "    embedding_index[word]=coefs\n",
    "f.close()\n",
    "\n",
    "print(\"found %s word vectors\",len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "embedding_matrix=np.zeros((vocab_size,embedding_dim))\n",
    "\n",
    "for word, i in wordtoix.items():\n",
    "    embedding_vector=embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(2048,))\n",
    "fe1=Dropout(0.5)(inputs1)\n",
    "fe2=Dense(256,activation='relu')(fe1)\n",
    "inputs2=Input(shape=(max_length,))\n",
    "\n",
    "se1=Embedding(vocab_size,embedding_dim,mask_zero=True)(inputs2)\n",
    "se2=Dropout(0.5)(se1)\n",
    "se3=LSTM(256)(se2)\n",
    "decoder1=add([fe2,se3])\n",
    "decoder2=Dense(256,activation='relu')(decoder1)\n",
    "outputs=Dense(vocab_size,activation='softmax')(decoder2)\n",
    "model=Model(inputs=[inputs1,inputs2],outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=9\n",
    "number_pics_per_batch=3\n",
    "steps=len(descriptions)//number_pics_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del descriptions['image_name']\n",
    "del descriptions['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.save('./model_weights/model_'+str(0)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs+1):\n",
    "    generator=data_generator(descriptions,train_features,wordtoix,max_length,number_pics_per_batch)\n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "    model.save('./model_weights/model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "new_model=tf.keras.models.load_model('./model_weights/model_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001))\n",
    "epochs = 10\n",
    "number_pics_per_bath = 6\n",
    "steps = len(descriptions)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs+1):\n",
    "    generator=data_generator(descriptions,train_features,wordtoix,max_length,number_pics_per_batch)\n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "    model.save('./model_weights/model_'+str(i+10)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model=tf.keras.models.load_model('./model_weights/final_model.h5')\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedySearch(photo):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = ixtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder='./test/'\n",
    "test_images=glob.glob(test_folder+'*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time()\n",
    "encoding_test={}\n",
    "for img in test_images:\n",
    "    encoding_test[img[len(test_folder):]]=encode(img)\n",
    "    print(\"time tken in second=\",time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics=list(encoding_test.keys())\n",
    "for pic in pics:\n",
    "    image=encoding_test[pic].reshape((1,2048))\n",
    "    print(\"greedy:\",greedySearch(image))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
